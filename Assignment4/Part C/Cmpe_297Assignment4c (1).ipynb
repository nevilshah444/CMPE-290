{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f953445a3384d2889e5a03d1f6f5f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62ce38170d574d15825307baf64329a0",
              "IPY_MODEL_7993a0711e0148338f9b5ae0fde6cb0b",
              "IPY_MODEL_45be2798cc27430e9def002fdbd73c1c"
            ],
            "layout": "IPY_MODEL_bc5bc7d1f449448d8577e78d85be66ad"
          }
        },
        "62ce38170d574d15825307baf64329a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228a6de5d6fb4741843f91bb0f42b89c",
            "placeholder": "​",
            "style": "IPY_MODEL_062809f478684679893c992eddb8f451",
            "value": "Downloading: 100%"
          }
        },
        "7993a0711e0148338f9b5ae0fde6cb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ebe1b0850c4c52a0a31546c6830065",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07bbfd7de3854548becb7f7e7cb32004",
            "value": 231508
          }
        },
        "45be2798cc27430e9def002fdbd73c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c84b27088b4b0580b82d5cc028d86b",
            "placeholder": "​",
            "style": "IPY_MODEL_513a6d79f8794ae992ebd3d4912d5be2",
            "value": " 232k/232k [00:00&lt;00:00, 289kB/s]"
          }
        },
        "bc5bc7d1f449448d8577e78d85be66ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228a6de5d6fb4741843f91bb0f42b89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062809f478684679893c992eddb8f451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28ebe1b0850c4c52a0a31546c6830065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07bbfd7de3854548becb7f7e7cb32004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8c84b27088b4b0580b82d5cc028d86b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513a6d79f8794ae992ebd3d4912d5be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a15405798684466a04ecc45ba900288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60af1958f8244c3692c6e71dfcc39a36",
              "IPY_MODEL_dac599f5ed744b4b957528de8f909e48",
              "IPY_MODEL_d19d7fa5d1ce426eb69344a3b3150472"
            ],
            "layout": "IPY_MODEL_0087f0bc7c5545bfa386a5efe82fc45e"
          }
        },
        "60af1958f8244c3692c6e71dfcc39a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35591f2ae9eb4ebfa8cdfb166f515b2c",
            "placeholder": "​",
            "style": "IPY_MODEL_e4a78f1a0dd544b188e5586283ee3895",
            "value": "Downloading: 100%"
          }
        },
        "dac599f5ed744b4b957528de8f909e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a54917dbda847e59ad70b8aa07d83af",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_006ae3b9857d4eada4f081ef06819c32",
            "value": 28
          }
        },
        "d19d7fa5d1ce426eb69344a3b3150472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47751ac2cc7441b78c07070d5aef45fe",
            "placeholder": "​",
            "style": "IPY_MODEL_474b942d579148e2a07426aebe41cf3d",
            "value": " 28.0/28.0 [00:00&lt;00:00, 872B/s]"
          }
        },
        "0087f0bc7c5545bfa386a5efe82fc45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35591f2ae9eb4ebfa8cdfb166f515b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a78f1a0dd544b188e5586283ee3895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a54917dbda847e59ad70b8aa07d83af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "006ae3b9857d4eada4f081ef06819c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47751ac2cc7441b78c07070d5aef45fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474b942d579148e2a07426aebe41cf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86f6ecc31acf4af4b57d97fc5949f6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5ca494d8e4d4d0794ccbf205ad87272",
              "IPY_MODEL_f393b0198058429580d95090dc214e29",
              "IPY_MODEL_f9d3cdf0edab44918e80eb5ed9accaf6"
            ],
            "layout": "IPY_MODEL_b76d3286fea84488a17fdc69e717852b"
          }
        },
        "a5ca494d8e4d4d0794ccbf205ad87272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3ac20af5f840f5976952f9307bcdfb",
            "placeholder": "​",
            "style": "IPY_MODEL_861f667f37a84ec8996e482d80513b9b",
            "value": "Downloading: 100%"
          }
        },
        "f393b0198058429580d95090dc214e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0d1d24d1ab4d509477c53b7a9a4148",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0596f30ef7bf43a0bc1dbe81550fd1e7",
            "value": 570
          }
        },
        "f9d3cdf0edab44918e80eb5ed9accaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e55649112f34dde92d08c4d489502d5",
            "placeholder": "​",
            "style": "IPY_MODEL_b34aef7c6ad94c99a75f83c8a1fc16c3",
            "value": " 570/570 [00:00&lt;00:00, 6.03kB/s]"
          }
        },
        "b76d3286fea84488a17fdc69e717852b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3ac20af5f840f5976952f9307bcdfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861f667f37a84ec8996e482d80513b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0d1d24d1ab4d509477c53b7a9a4148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0596f30ef7bf43a0bc1dbe81550fd1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e55649112f34dde92d08c4d489502d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34aef7c6ad94c99a75f83c8a1fc16c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8e4193eaea24567a48eddeaa775bbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68abda8bda9b4d2992135adda05d99b0",
              "IPY_MODEL_42e225a70a4e4dec88cd4be810b9ade7",
              "IPY_MODEL_f970bc7e7d2847bcbea58c1bbce4d3d5"
            ],
            "layout": "IPY_MODEL_aaf0f44ba5934e6bab6f01ffd587512a"
          }
        },
        "68abda8bda9b4d2992135adda05d99b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_307b9ab4221546a683580f1532d00e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_1ddfcd0d49ba4511b102dba37ac245e4",
            "value": "Downloading: 100%"
          }
        },
        "42e225a70a4e4dec88cd4be810b9ade7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d367a7d871fc4f6fb6cda8be83c901a5",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0196cf63b254bde87745159b4714a14",
            "value": 440473133
          }
        },
        "f970bc7e7d2847bcbea58c1bbce4d3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e622b532aff64c0f89ba15cc1c3fc310",
            "placeholder": "​",
            "style": "IPY_MODEL_dd037054899f426c98b55841059dbd33",
            "value": " 440M/440M [00:15&lt;00:00, 56.7MB/s]"
          }
        },
        "aaf0f44ba5934e6bab6f01ffd587512a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307b9ab4221546a683580f1532d00e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ddfcd0d49ba4511b102dba37ac245e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d367a7d871fc4f6fb6cda8be83c901a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0196cf63b254bde87745159b4714a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e622b532aff64c0f89ba15cc1c3fc310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd037054899f426c98b55841059dbd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 4C:\n",
        "\n",
        "Aim:  Implement a colab of  metalearning on top of BERT"
      ],
      "metadata": {
        "id": "rOgKtTxrryqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the dataset\n"
      ],
      "metadata": {
        "id": "R_vUlbdhr7Mx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eytkru1h61SA",
        "outputId": "26c72cfd-e7a3-4048-e526-efb84245c410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOOL LIKE ME. AND COMFORTABLE. AND RELATIVELY CHEAP. I'LL ALWAYS KEEP A PAIR OF STAN SMITH'S AROUND FOR WEEKENDS\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': 'These sunglasses are all right. They were a little crooked, but still cool..',\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': \"I don't see the difference between these bodysuits and the more expensive ones. Fits my boy just right\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': 'Very nice basic clothing. I think the size is fine. I really like being able to find these shades of green, though I have decided the lighter shade is really a feminine color. This is the only brand that I can find these muted greens',\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': 'I love these socks. They fit great (my 15 month old daughter has thick ankles) and she can zoom around on the kitchen floor and not take a nose dive into things. :',\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Let inspect the data\n",
        "import json\n",
        "from random import shuffle\n",
        "reviews = json.load(open('dataset.json'))\n",
        "\n",
        "reviews[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the transformer module in google colab"
      ],
      "metadata": {
        "id": "EQ1EOXVxr-Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA6LjMud94FV",
        "outputId": "7271c25c-3325-46a6-db1e-c5999640e4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 74.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "mention_domain = [r['domain'] for r in reviews]\n",
        "Counter(mention_domain)"
      ],
      "metadata": {
        "id": "oAlaYzDz9Xyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393f9ce7-354e-44c1-8cc1-25bd5c53bc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'apparel': 1717,\n",
              "         'baby': 1107,\n",
              "         'beauty': 993,\n",
              "         'books': 921,\n",
              "         'camera_&_photo': 1086,\n",
              "         'cell_phones_&_service': 698,\n",
              "         'dvd': 893,\n",
              "         'electronics': 1277,\n",
              "         'grocery': 1100,\n",
              "         'health_&_personal_care': 1429,\n",
              "         'jewelry_&_watches': 1086,\n",
              "         'kitchen_&_housewares': 1390,\n",
              "         'magazines': 1133,\n",
              "         'music': 1007,\n",
              "         'outdoor_living': 980,\n",
              "         'software': 1029,\n",
              "         'sports_&_outdoors': 1336,\n",
              "         'toys_&_games': 1363,\n",
              "         'video': 1010,\n",
              "         'automotive': 100,\n",
              "         'computer_&_video_games': 100,\n",
              "         'office_products': 100})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating meta learning tasks"
      ],
      "metadata": {
        "id": "vTDdgEh1sFnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import collections\n",
        "import random\n",
        "import json, pickle\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "LABEL_MAP  = {'positive':0, 'negative':1, 0:'positive', 1:'negative'}\n",
        "\n",
        "class MetaTask(Dataset):\n",
        "    \n",
        "    def __init__(self, examples, num_task, k_support, k_query, tokenizer):\n",
        "        \"\"\"\n",
        "        :param samples: list of samples\n",
        "        :param num_task: number of training tasks.\n",
        "        :param k_support: number of support sample per task\n",
        "        :param k_query: number of query sample per task\n",
        "        \"\"\"\n",
        "        self.examples = examples\n",
        "        random.shuffle(self.examples)\n",
        "        \n",
        "        self.num_task = num_task\n",
        "        self.k_support = k_support\n",
        "        self.k_query = k_query\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = 128\n",
        "        self.create_batch(self.num_task)\n",
        "    \n",
        "    def create_batch(self, num_task):\n",
        "        self.supports = []  # support set\n",
        "        self.queries = []  # query set\n",
        "        \n",
        "        for b in range(num_task):  # for each task\n",
        "            # 1.select domain randomly\n",
        "            domain = random.choice(self.examples)['domain']\n",
        "            domainExamples = [e for e in self.examples if e['domain'] == domain]\n",
        "            \n",
        "            # 1.select k_support + k_query examples from domain randomly\n",
        "            selected_examples = random.sample(domainExamples,self.k_support + self.k_query)\n",
        "            random.shuffle(selected_examples)\n",
        "            exam_train = selected_examples[:self.k_support]\n",
        "            exam_test  = selected_examples[self.k_support:]\n",
        "            \n",
        "            self.supports.append(exam_train)\n",
        "            self.queries.append(exam_test)\n",
        "\n",
        "    def create_feature_set(self,examples):\n",
        "        all_input_ids      = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_attention_mask = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_segment_ids    = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_label_ids      = torch.empty(len(examples), dtype = torch.long)\n",
        "\n",
        "        for id_,example in enumerate(examples):\n",
        "            input_ids = tokenizer.encode(example['text'])\n",
        "            attention_mask = [1] * len(input_ids)\n",
        "            segment_ids    = [0] * len(input_ids)\n",
        "\n",
        "            while len(input_ids) < self.max_seq_length:\n",
        "                input_ids.append(0)\n",
        "                attention_mask.append(0)\n",
        "                segment_ids.append(0)\n",
        "\n",
        "            label_id = LABEL_MAP[example['label']]\n",
        "            all_input_ids[id_] = torch.Tensor(input_ids).to(torch.long)\n",
        "            all_attention_mask[id_] = torch.Tensor(attention_mask).to(torch.long)\n",
        "            all_segment_ids[id_] = torch.Tensor(segment_ids).to(torch.long)\n",
        "            all_label_ids[id_] = torch.Tensor([label_id]).to(torch.long)\n",
        "\n",
        "        tensor_set = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)  \n",
        "        return tensor_set\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        support_set = self.create_feature_set(self.supports[index])\n",
        "        query_set   = self.create_feature_set(self.queries[index])\n",
        "        return support_set, query_set\n",
        "\n",
        "    def __len__(self):\n",
        "        # as we have built up to batchsz of sets, you can sample some small batch size of sets.\n",
        "        return self.num_task"
      ],
      "metadata": {
        "id": "XJF0Tcxm9aVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split meta training and meta testing"
      ],
      "metadata": {
        "id": "C2jQEUFpsLuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_resource_domains = [\"office_products\", \"automotive\", \"computer_&_video_games\"]\n",
        "train_examples = [r for r in reviews if r['domain'] not in low_resource_domains]\n",
        "test_examples = [r for r in reviews if r['domain'] in low_resource_domains]\n",
        "print(len(train_examples), len(test_examples))"
      ],
      "metadata": {
        "id": "5qJkO2-q9fbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0aebf60-a466-4490-bd6d-18ec7582f8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21555 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "train = MetaTask(train_examples, num_task = 100, k_support=100, k_query=30, tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "Su7Y4ft89jEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "5f953445a3384d2889e5a03d1f6f5f97",
            "62ce38170d574d15825307baf64329a0",
            "7993a0711e0148338f9b5ae0fde6cb0b",
            "45be2798cc27430e9def002fdbd73c1c",
            "bc5bc7d1f449448d8577e78d85be66ad",
            "228a6de5d6fb4741843f91bb0f42b89c",
            "062809f478684679893c992eddb8f451",
            "28ebe1b0850c4c52a0a31546c6830065",
            "07bbfd7de3854548becb7f7e7cb32004",
            "b8c84b27088b4b0580b82d5cc028d86b",
            "513a6d79f8794ae992ebd3d4912d5be2",
            "0a15405798684466a04ecc45ba900288",
            "60af1958f8244c3692c6e71dfcc39a36",
            "dac599f5ed744b4b957528de8f909e48",
            "d19d7fa5d1ce426eb69344a3b3150472",
            "0087f0bc7c5545bfa386a5efe82fc45e",
            "35591f2ae9eb4ebfa8cdfb166f515b2c",
            "e4a78f1a0dd544b188e5586283ee3895",
            "6a54917dbda847e59ad70b8aa07d83af",
            "006ae3b9857d4eada4f081ef06819c32",
            "47751ac2cc7441b78c07070d5aef45fe",
            "474b942d579148e2a07426aebe41cf3d",
            "86f6ecc31acf4af4b57d97fc5949f6ed",
            "a5ca494d8e4d4d0794ccbf205ad87272",
            "f393b0198058429580d95090dc214e29",
            "f9d3cdf0edab44918e80eb5ed9accaf6",
            "b76d3286fea84488a17fdc69e717852b",
            "7c3ac20af5f840f5976952f9307bcdfb",
            "861f667f37a84ec8996e482d80513b9b",
            "ac0d1d24d1ab4d509477c53b7a9a4148",
            "0596f30ef7bf43a0bc1dbe81550fd1e7",
            "3e55649112f34dde92d08c4d489502d5",
            "b34aef7c6ad94c99a75f83c8a1fc16c3"
          ]
        },
        "outputId": "ca3d63fe-717a-4211-cb47-af81efe60271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f953445a3384d2889e5a03d1f6f5f97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a15405798684466a04ecc45ba900288"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86f6ecc31acf4af4b57d97fc5949f6ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take a glance at the first two samples from support set of 1st meta-task\n",
        "train.supports[0][:2]"
      ],
      "metadata": {
        "id": "u147HZDJ9mcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf7265e-620a-402a-ccb4-f331be63fec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"This cooking utensil is unlike any other. its intricate design is for the dumbest cooker or even a gormet french dude. Little do you know that this fork can be used as a stress reliever as well. say, for example, that your meat is not turning out well at all, infact it doesn't seem to look like meat anymore just crap, well with this fork you can whack the meat, stab it, and then hurl it across the yard and, trust me, you'll feel much better\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'outdoor_living'},\n",
              " {'text': 'The repeller works fine at repelling, but when on the \"rodent\" setting it makes an audible chirping noise that\\'s annoying so it can be used only in remote locations where people don\\'t normally go.The reason we bought this model was because it can run on batteries and we wanted it for an outer shed, but the manual says that it\\'ll only run two or three days on battery power, making it absolutely worthless for this use',\n",
              "  'label': 'negative',\n",
              "  'domain': 'outdoor_living'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Information of the 1st meta-task. It contains two TensorDataset: support set and query set\n",
        "train[0]"
      ],
      "metadata": {
        "id": "ZZKdAbVh-hVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eecb350-382e-4d1d-8c45-d39960cba81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataset.TensorDataset at 0x7fdc64c74390>,\n",
              " <torch.utils.data.dataset.TensorDataset at 0x7fdbf3bc9310>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let take a look at the first two samples from support set\n",
        "train[0][0][:2]"
      ],
      "metadata": {
        "id": "VUAICRP3-j5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506c1d74-a6e3-4c0b-dd22-53c34490d936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,  2023,  8434, 21183,  6132,  4014,  2003,  4406,  2151,  2060,\n",
              "           1012,  2049, 17796,  2640,  2003,  2005,  1996, 12873,  4355, 16546,\n",
              "           2099,  2030,  2130,  1037,  2175, 10867,  3388,  2413, 12043,  1012,\n",
              "           2210,  2079,  2017,  2113,  2008,  2023,  9292,  2064,  2022,  2109,\n",
              "           2004,  1037,  6911, 15804,  2099,  2004,  2092,  1012,  2360,  1010,\n",
              "           2005,  2742,  1010,  2008,  2115,  6240,  2003,  2025,  3810,  2041,\n",
              "           2092,  2012,  2035,  1010,  1999,  7011,  6593,  2009,  2987,  1005,\n",
              "           1056,  4025,  2000,  2298,  2066,  6240,  4902,  2074, 10231,  1010,\n",
              "           2092,  2007,  2023,  9292,  2017,  2064,  1059,  3270,  3600,  1996,\n",
              "           6240,  1010, 17079,  2009,  1010,  1998,  2059, 15876, 12190,  2009,\n",
              "           2408,  1996,  4220,  1998,  1010,  3404,  2033,  1010,  2017,  1005,\n",
              "           2222,  2514,  2172,  2488,   102,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [  101,  1996, 16360, 24038,  2573,  2986,  2012, 16360, 23918,  1010,\n",
              "           2021,  2043,  2006,  1996,  1000,  8469,  3372,  1000,  4292,  2009,\n",
              "           3084,  2019, 19525,  9610, 14536,  2075,  5005,  2008,  1005,  1055,\n",
              "          15703,  2061,  2009,  2064,  2022,  2109,  2069,  1999,  6556,  5269,\n",
              "           2073,  2111,  2123,  1005,  1056,  5373,  2175,  1012,  1996,  3114,\n",
              "           2057,  4149,  2023,  2944,  2001,  2138,  2009,  2064,  2448,  2006,\n",
              "          10274,  1998,  2057,  2359,  2009,  2005,  2019,  6058,  8328,  1010,\n",
              "           2021,  1996,  6410,  2758,  2008,  2009,  1005,  2222,  2069,  2448,\n",
              "           2048,  2030,  2093,  2420,  2006,  6046,  2373,  1010,  2437,  2009,\n",
              "           7078, 22692,  2005,  2023,  2224,   102,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
              " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([0, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training meta"
      ],
      "metadata": {
        "id": "7_zsZPV3sPaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "def random_seed(value):\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "    torch.manual_seed(value)\n",
        "    torch.cuda.manual_seed(value)\n",
        "    np.random.seed(value)\n",
        "    random.seed(value)\n",
        "\n",
        "def create_batch_of_tasks(taskset, is_shuffle = True, batch_size = 4):\n",
        "    idxs = list(range(0,len(taskset)))\n",
        "    if is_shuffle:\n",
        "        random.shuffle(idxs)\n",
        "    for i in range(0,len(idxs), batch_size):\n",
        "        yield [taskset[idxs[i]] for i in range(i, min(i + batch_size,len(taskset)))]\n",
        "\n",
        "class TrainingArgs:\n",
        "    def __init__(self):\n",
        "        self.num_labels = 2\n",
        "        self.meta_epoch=10\n",
        "        self.k_spt=80\n",
        "        self.k_qry=20\n",
        "        self.outer_batch_size = 2\n",
        "        self.inner_batch_size = 12\n",
        "        self.outer_update_lr = 5e-5\n",
        "        self.inner_update_lr = 5e-5\n",
        "        self.inner_update_step = 10\n",
        "        self.inner_update_step_eval = 40\n",
        "        self.bert_model = 'bert-base-uncased'\n",
        "        self.num_task_train = 500\n",
        "        self.num_task_test = 5\n",
        "\n",
        "args = TrainingArgs()"
      ],
      "metadata": {
        "id": "fHRVVlpP-ml0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Meta Learner"
      ],
      "metadata": {
        "id": "SZRZAlHssStS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BertForSequenceClassification\n",
        "from copy import deepcopy\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Learner(nn.Module):\n",
        "    \"\"\"\n",
        "    Meta Learner\n",
        "    \"\"\"\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        :param args:\n",
        "        \"\"\"\n",
        "        super(Learner, self).__init__()\n",
        "        \n",
        "        self.num_labels = args.num_labels\n",
        "        self.outer_batch_size = args.outer_batch_size\n",
        "        self.inner_batch_size = args.inner_batch_size\n",
        "        self.outer_update_lr  = args.outer_update_lr\n",
        "        self.inner_update_lr  = args.inner_update_lr\n",
        "        self.inner_update_step = args.inner_update_step\n",
        "        self.inner_update_step_eval = args.inner_update_step_eval\n",
        "        self.bert_model = args.bert_model\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.bert_model, num_labels = self.num_labels)\n",
        "        self.outer_optimizer = Adam(self.model.parameters(), lr=self.outer_update_lr)\n",
        "        self.model.train()\n",
        "\n",
        "    def forward(self, batch_tasks, training = True):\n",
        "        \"\"\"\n",
        "        batch = [(support TensorDataset, query TensorDataset),\n",
        "                 (support TensorDataset, query TensorDataset),\n",
        "                 (support TensorDataset, query TensorDataset),\n",
        "                 (support TensorDataset, query TensorDataset)]\n",
        "        \n",
        "        # support = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)\n",
        "        \"\"\"\n",
        "        task_accs = []\n",
        "        sum_gradients = []\n",
        "        num_task = len(batch_tasks)\n",
        "        num_inner_update_step = self.inner_update_step if training else self.inner_update_step_eval\n",
        "\n",
        "        for task_id, task in enumerate(batch_tasks):\n",
        "            support = task[0]\n",
        "            query   = task[1]\n",
        "            \n",
        "            fast_model = deepcopy(self.model)\n",
        "            fast_model.to(self.device)\n",
        "            support_dataloader = DataLoader(support, sampler=RandomSampler(support),\n",
        "                                            batch_size=self.inner_batch_size)\n",
        "            \n",
        "            inner_optimizer = Adam(fast_model.parameters(), lr=self.inner_update_lr)\n",
        "            fast_model.train()\n",
        "            \n",
        "            print('----Task',task_id, '----')\n",
        "            for i in range(0,num_inner_update_step):\n",
        "                all_loss = []\n",
        "                for inner_step, batch in enumerate(support_dataloader):\n",
        "                    \n",
        "                    batch = tuple(t.to(self.device) for t in batch)\n",
        "                    input_ids, attention_mask, segment_ids, label_id = batch\n",
        "                    outputs = fast_model(input_ids, attention_mask, segment_ids, labels = label_id)\n",
        "                    \n",
        "                    loss = outputs[0]              \n",
        "                    loss.backward()\n",
        "                    inner_optimizer.step()\n",
        "                    inner_optimizer.zero_grad()\n",
        "                    \n",
        "                    all_loss.append(loss.item())\n",
        "                \n",
        "                if i % 4 == 0:\n",
        "                    print(\"Inner Loss: \", np.mean(all_loss))\n",
        "            \n",
        "            fast_model.to(torch.device('cpu'))\n",
        "            \n",
        "            if training:\n",
        "                meta_weights = list(self.model.parameters())\n",
        "                fast_weights = list(fast_model.parameters())\n",
        "\n",
        "                gradients = []\n",
        "                for i, (meta_params, fast_params) in enumerate(zip(meta_weights, fast_weights)):\n",
        "                    gradient = meta_params - fast_params\n",
        "                    if task_id == 0:\n",
        "                        sum_gradients.append(gradient)\n",
        "                    else:\n",
        "                        sum_gradients[i] += gradient\n",
        "\n",
        "            fast_model.to(self.device)\n",
        "            fast_model.eval()\n",
        "            with torch.no_grad():\n",
        "                query_dataloader = DataLoader(query, sampler=None, batch_size=len(query))\n",
        "                query_batch = iter(query_dataloader).next()\n",
        "                query_batch = tuple(t.to(self.device) for t in query_batch)\n",
        "                q_input_ids, q_attention_mask, q_segment_ids, q_label_id = query_batch\n",
        "                q_outputs = fast_model(q_input_ids, q_attention_mask, q_segment_ids, labels = q_label_id)\n",
        "\n",
        "                q_logits = F.softmax(q_outputs[1],dim=1)\n",
        "                pre_label_id = torch.argmax(q_logits,dim=1)\n",
        "                pre_label_id = pre_label_id.detach().cpu().numpy().tolist()\n",
        "                q_label_id = q_label_id.detach().cpu().numpy().tolist()\n",
        "\n",
        "                acc = accuracy_score(pre_label_id,q_label_id)\n",
        "                task_accs.append(acc)\n",
        "            \n",
        "            fast_model.to(torch.device('cpu'))\n",
        "            del fast_model, inner_optimizer\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        if training:\n",
        "            # Average gradient across tasks\n",
        "            for i in range(0,len(sum_gradients)):\n",
        "                sum_gradients[i] = sum_gradients[i] / float(num_task)\n",
        "\n",
        "            #Assign gradient for original model, then using optimizer to update its weights\n",
        "            for i, params in enumerate(self.model.parameters()):\n",
        "                params.grad = sum_gradients[i]\n",
        "\n",
        "            self.outer_optimizer.step()\n",
        "            self.outer_optimizer.zero_grad()\n",
        "            \n",
        "            del sum_gradients\n",
        "            gc.collect()\n",
        "        \n",
        "        return np.mean(task_accs)"
      ],
      "metadata": {
        "id": "_rV4nT1V-qKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner = Learner(args)"
      ],
      "metadata": {
        "id": "fK4DUH3E-57D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "b8e4193eaea24567a48eddeaa775bbf1",
            "68abda8bda9b4d2992135adda05d99b0",
            "42e225a70a4e4dec88cd4be810b9ade7",
            "f970bc7e7d2847bcbea58c1bbce4d3d5",
            "aaf0f44ba5934e6bab6f01ffd587512a",
            "307b9ab4221546a683580f1532d00e8e",
            "1ddfcd0d49ba4511b102dba37ac245e4",
            "d367a7d871fc4f6fb6cda8be83c901a5",
            "f0196cf63b254bde87745159b4714a14",
            "e622b532aff64c0f89ba15cc1c3fc310",
            "dd037054899f426c98b55841059dbd33"
          ]
        },
        "outputId": "5a7b4a23-7588-4f40-8891-5f032396576f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8e4193eaea24567a48eddeaa775bbf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed(123)\n",
        "test = MetaTask(test_examples, num_task = 3, k_support=40, k_query=20, tokenizer = tokenizer)\n",
        "random_seed(int(time.time() % 10))"
      ],
      "metadata": {
        "id": "l2Xj9VPa_kQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.supports[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gff9e6ol_meS",
        "outputId": "f6289952-f699-4ef6-f546-97fe6be085ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'i have been playing the madden series since i was a kid and this game is really good. the games just keep getting better and better as each year passes. everything in this game is worth the money i strongly reccommend it',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'I noticed there were not many new items in this game, I found this the advertising for this game to be deceiving. This expansion ws not worth the money',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"This pack offered very little of anything. The decor (very little of it) is uninspired. I was hoping to get some good artwork at least. I know a lot of people don't like to download from fan sites but don't waste your money on this junk. Believe me fansites have much better and more creative stuff for your sims and most of it is free, and none of it cost as much as this glamour life stuff pack did. This is the first and last stuff pack that I will ever buy\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"In case you havent' noticed this is a controller not a game. So as far as the controller goes, it works great and I have not had a single problem with it.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'DO NOT USE THIS the dvd thing causes the xbox to break. when u play games the disk doesnt constantly spin. it reads some and takes break so it doesnt over heat. when it reads a dvd, it must constantly spin. the dvd playback kit fryed my xbox. at most \"best buy\"s you can buy a dvdplayer that functions better for less money than the one for xbox.',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I am so glad I purchased the Logitech Mic for PS2. The quality of the sound is awesome, and my kids are having a blast with it. The price is reasonable. My kids take very good care of things, but I'm not so sure that it could withstand any mistreatment. I will probably end up buying another one\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'Seriously. You could just hold up a finger close to the camera lens and just wave it back and forth. That is a perfect way of cheating. The game is not bad after all.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"Beautiful graphics and nice storyline, but the amount of times the game freezes or you receive an error is just awful! Not to mention, the monsters level up with you so you'll never be at an advantage. You could pretty much beat the game at level 5\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I hate this game its the worst game I've ever played\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'SMALL MEMORY WHICH MEANS THAT U CAN ONLY PUT 1 SAVE ON IT SO U HAVE TO RUN BACK TO YOUR COMP EVERYTIME U WANNA SAVE!!! AND SOFTWARE IS VEERY CONFUSING!!! HORRIBLE BUY!!! I RETURNED THE PIECE OF JUNK!!',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'This is a great cable for your HD TV while playing you Sony Playstation 2. It give very crisp and clear images, much better than the cable that comes with the playstation.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"First off the eyetoy is a great game/peripheral. Next it's getting some new games, as well as it will be useable on the next gen console PS3. Third it is usable as a webcam on the pc. In fact, it is a fantastic webcam. Only you need to download a .inf (a driver) for the webcam. There's tutorials out there. Google it\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"We got a group of 5 friends together to do Guitar Hero 1 and 2, DDR, and now Karaoke Revolution Party. It's freaking cool. The songs list is very good and there's something for everyone. Easy to figure out too\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"This game has StarForce copy protection, which is software that you do not want on your computer. Reportedly, it replaces your CD and/or DVD drivers, and often causes extreme hardware and software problems. I've been a victim of the software problems, it basically crippled my very expensive SCSI scanners and it was extremely difficult to figure out what was doing it. It could be the best game that's ever been produced, but anyone who's had the StarForce experience is going to steer clear\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I've played them all and enjoyed them all. Sorry this was the last one\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I gave it one star because there was no way to give it less.This game when played on the X Box was great. So when it came out for PC I bought it. BIG MISTAKE! The control are too hard to learn. And when you are in a battle you can't stop to think which keys when used together work. There are too many keys that you need to push together to do even the simplest thing. I wasted my money on this game. I deleted it and will never play it. Don't waste your money\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I bought the KR Party bundle for my boyfriend's daughter for her birthday. She loves the game, but it has only been about two weeks and the mic is dead. It started with the static for a while, but then while I was singing, it just died completely. I know I'm not a great singer, but I'm not THAT bad\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"Don't buy this here - it is selling for $49.99 at Best Buy (bestbuy.com). Wait until they lower the price on Amazon\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"If you are looking for an XBOX vertsion of another chapter in MechWarrior series, this ISN'T it. This is an extemely dumbed-down version of MW. Even if you (Mechwarrior fans) forget about having no customization, remember this: You can only fire one weapon at at time. You have to cycle between lazers, cannons and rockets. I was bored after about 5 minutes.Again, people who never played MW series may like this game better\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"If you're going to play Karaoke Revolution, this is the mic for you. I now have 2 so that my wife and I can play in duet mode. It's much better than the headset. For just 17 bucks, you can have a 'real' mic that feels so much more natural. If you play KR a lot, invest in this microphone\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'I am extreamly dissapointd with this game. Every section and mission is exactly the same with the exception of the location. There is absolutly no skill involved in beating the game which i was able to do in 3 sittings.',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"Shouldn't you people know by now?Say it with me:NEVER BUY MOVIE GAMES.A friend of mine bought it and it was horrible.It was way too easy to die in,etc,etc,etc.Hey listen.Keep you money.Your investment isn't in here\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"why is it that 3rd party memory cards can store at least double the information that these can? These memory cards are way over priced. I love PS2. It's one of the best systems I have ever played and owned, but this memory card stuff is a scam. I already own 2 cards and I need more.\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'This is Supposed to be an x-box cleaner, but the system does not read the disc. A shoddy product',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'If you like Diablo 1..... this is exactly the same game... only improved 300% percent. If not for Blizzards Bnet and all the multiplayer options I would say that this game is also better than Diablo',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"People, I don't know what you see in this game. It's not really a bad game, it's just an average arcade shooter. More often than not, I can't even hit the enemy because the action occurs so quickly. I pop out from behind something and I'm dead meat. Pick up the second one to see what it was like to play a good Time Crisis game\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I love this game. My daughter and I are big Ratchet and Clank fans and look for games with similiar play. We found that in the Incredibles game. It's exciting and challenging. As we get playing it , I wonder if it is too easy at times, but then I get to a spot that I can't accomplish until I do it 10 times. My favorite thing about the game is , after conquering the first level as Mr. Incredible, you then get to be Mrs. Incredible, Dash, Violet, etc. Great fun\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'Tediously long and weary. Nothing interesting, just a lot of borrowed ideas from RTCW, HL2, etc. I am sick of this',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I saw a DVD player at Target for $30 yesterday. I especially don't see the need for the xbox 360 remote if it's $40!! Space-saving, maybe???\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'This game is really good.Theres a wide varity of lvls to play,and a very good multyplayer system.The game only has a few faults, like a blown up frigate in space sometimes goes through the capital ship.The game also gets a little boring after a while.Besides that,its a great game',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'returned item for refund; found it cheaper at Toys R U',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"This is a perfect example of false advertisement. If you're like the many that i've heard of trying to order a remote for the Playstation 2, Don't order this one unless you have a newer model. The picture shows an IR unit but it doesn't come with one. So save yourself the hassle and don't order this\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': \"I bought it for my grandson and have not heard any complaints as a matter of fact I haven't heard any noise he is to busy playing it\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'Rockstar games are rocking the gamers world,one more of the great titles from the leaders in adult games',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'My nephew really needed a new controller. So I ordered this along with a game for his birthday. The game was received fine, but he never received the controller. I finally got notification of shipping delay several weeks later. Yet the controller still listed as ships within 24 hours on Amazon. The delays kept coming and eventually it just turned into a cancelled order by Amazon. So the 1 star is for the service, the delay, and the lack of full explanation. Who knows, the controller could have been wonderful??',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'I have all the \"Grand Theft\" games and this is one of my favs.I highly recommend it and all the others.I recently purchased \"Liberty City\" Awesome',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'The best way to play this game is to skip the missions and just start havoc in the city. Fight the gangs and police, attack the citizens and steal cars!! If you are able to find some of the cheat codes off the Internet, then this is where the fun really begins! These secrets can give you armor, weapons and even a tank (this is only listing a few)! As always parents, research a video game before you buy it for your 7 year old.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'These Component AV cables make a world of difference in video quality. Especially on HDTV. Some Images now appear pixelated, this may be the game I am playing. But everything else is smooth, crisp, and clear. Text is three times as easy to read. I reccomend these for any HDTV owner',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'this game is really bad I mean everything about it. they took so long to make this and for what.its just a waste off time and your money I gave it 1star because the guns are the best thing about this crap gam',\n",
              "  'label': 'negative',\n",
              "  'domain': 'computer_&_video_games'},\n",
              " {'text': 'This controller feels great in your hands. In fact, after using this controller for awhile, my batteries went low and I had to switch back to the Dualshock controller. The Dualshock felt wierd in my hands. The response of the controller is good. I have had the controller for a long time now and have not experienced any lag time. One down side to the controller was that i returned two controllers because they has stopped working in a short period of time. I guess the 3rd time is the charm because this one is working fine after almost a year',\n",
              "  'label': 'positive',\n",
              "  'domain': 'computer_&_video_games'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start training"
      ],
      "metadata": {
        "id": "QtrS9knSsXs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_step = 0\n",
        "\n",
        "for epoch in range(args.meta_epoch):\n",
        "    \n",
        "    train = MetaTask(train_examples, num_task = 500, k_support=80, k_query=20, tokenizer = tokenizer)\n",
        "    db = create_batch_of_tasks(train, is_shuffle = True, batch_size = args.outer_batch_size)\n",
        "\n",
        "    for step, task_batch in enumerate(db):\n",
        "        \n",
        "        f = open('log.txt', 'a')\n",
        "        \n",
        "        acc = learner(task_batch)\n",
        "        \n",
        "        print('Step:', step, '\\ttraining Acc:', acc)\n",
        "        f.write(str(acc) + '\\n')\n",
        "        \n",
        "        if global_step % 20 == 0:\n",
        "            random_seed(123)\n",
        "            print(\"\\n-----------------Testing Mode-----------------\\n\")\n",
        "            db_test = create_batch_of_tasks(test, is_shuffle = False, batch_size = 1)\n",
        "            acc_all_test = []\n",
        "\n",
        "            for test_batch in db_test:\n",
        "                acc = learner(test_batch, training = False)\n",
        "                acc_all_test.append(acc)\n",
        "\n",
        "            print('Step:', step, 'Test F1:', np.mean(acc_all_test))\n",
        "            f.write('Test' + str(np.mean(acc_all_test)) + '\\n')\n",
        "            \n",
        "            random_seed(int(time.time() % 10))\n",
        "        \n",
        "        global_step += 1\n",
        "        f.close()"
      ],
      "metadata": {
        "id": "0oTMgned_7ZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "840f7ed3-b967-47b4-d6b1-21d4df1c038f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----Task 0 ----\n",
            "Inner Loss:  0.6542116233280727\n",
            "Inner Loss:  0.009515790667917048\n",
            "Inner Loss:  0.0009387883058350001\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.7054317678724017\n",
            "Inner Loss:  0.04069525908146586\n",
            "Inner Loss:  0.0025243567901530434\n",
            "Step: 0 \ttraining Acc: 0.925\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5961832255125046\n",
            "Inner Loss:  0.04516174644231796\n",
            "Inner Loss:  0.004061911895405501\n",
            "Inner Loss:  0.0014117990504018962\n",
            "Inner Loss:  0.0009461945301154628\n",
            "Inner Loss:  0.0007003051432548091\n",
            "Inner Loss:  0.0005856912466697395\n",
            "Inner Loss:  0.0004995336348656565\n",
            "Inner Loss:  0.0004177009395789355\n",
            "Inner Loss:  0.00038187891914276406\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6925708502531052\n",
            "Inner Loss:  0.04133319575339556\n",
            "Inner Loss:  0.0032846852554939687\n",
            "Inner Loss:  0.0012863068550359458\n",
            "Inner Loss:  0.0009422632574569434\n",
            "Inner Loss:  0.0006912937387824059\n",
            "Inner Loss:  0.0005480638210428879\n",
            "Inner Loss:  0.000470508100988809\n",
            "Inner Loss:  0.00038032576412661\n",
            "Inner Loss:  0.0003881947632180527\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6110235452651978\n",
            "Inner Loss:  0.05601925868541002\n",
            "Inner Loss:  0.005244333413429558\n",
            "Inner Loss:  0.0017017768695950508\n",
            "Inner Loss:  0.0010716767865233123\n",
            "Inner Loss:  0.00083175279723946\n",
            "Inner Loss:  0.0006471147789852694\n",
            "Inner Loss:  0.0005600387376034632\n",
            "Inner Loss:  0.00047899342462187633\n",
            "Inner Loss:  0.0004347038848209195\n",
            "Step: 0 Test F1: 0.8333333333333334\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6339957799230304\n",
            "Inner Loss:  0.007775589491107634\n",
            "Inner Loss:  0.0011315983553816164\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.6765377351215908\n",
            "Inner Loss:  0.020692369767597744\n",
            "Inner Loss:  0.014663078689149447\n",
            "Step: 1 \ttraining Acc: 0.7749999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5113960206508636\n",
            "Inner Loss:  0.00859201277074005\n",
            "Inner Loss:  0.001243118429556489\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4063887872866222\n",
            "Inner Loss:  0.009535337598728282\n",
            "Inner Loss:  0.0014194376334281905\n",
            "Step: 2 \ttraining Acc: 0.825\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.477917771254267\n",
            "Inner Loss:  0.009480941974158798\n",
            "Inner Loss:  0.001702566148846277\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4299325942993164\n",
            "Inner Loss:  0.005518818240878838\n",
            "Inner Loss:  0.0014750030490436725\n",
            "Step: 3 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5064116503511157\n",
            "Inner Loss:  0.007824006823024579\n",
            "Inner Loss:  0.0013605309650301933\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4160400650330952\n",
            "Inner Loss:  0.010472979197012526\n",
            "Inner Loss:  0.0017969858267211489\n",
            "Step: 4 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3347864342587335\n",
            "Inner Loss:  0.008939307183027267\n",
            "Inner Loss:  0.0013731649378314614\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4344625047274998\n",
            "Inner Loss:  0.005923582706600428\n",
            "Inner Loss:  0.0011849172629549035\n",
            "Step: 5 \ttraining Acc: 0.825\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5749914071389607\n",
            "Inner Loss:  0.07557809446007013\n",
            "Inner Loss:  0.013743646775505372\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.21978868756975448\n",
            "Inner Loss:  0.0031873194633850028\n",
            "Inner Loss:  0.0010084120357143028\n",
            "Step: 6 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22740926380668366\n",
            "Inner Loss:  0.036081625414746146\n",
            "Inner Loss:  0.002425456602525498\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5133159330912999\n",
            "Inner Loss:  0.006380907725542784\n",
            "Inner Loss:  0.0013242560671642423\n",
            "Step: 7 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.37978051602840424\n",
            "Inner Loss:  0.004520986960934741\n",
            "Inner Loss:  0.001158460825016456\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4822907532964434\n",
            "Inner Loss:  0.004579132389543312\n",
            "Inner Loss:  0.0011446579758610045\n",
            "Step: 8 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2323304329599653\n",
            "Inner Loss:  0.15496515811953163\n",
            "Inner Loss:  0.003472969900550587\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3435652256011963\n",
            "Inner Loss:  0.0046957678028515405\n",
            "Inner Loss:  0.001153977562872959\n",
            "Step: 9 \ttraining Acc: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24960081013185637\n",
            "Inner Loss:  0.008713665684419019\n",
            "Inner Loss:  0.0014399528403633407\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4635572460080896\n",
            "Inner Loss:  0.02698945493570396\n",
            "Inner Loss:  0.0022885692305862904\n",
            "Step: 10 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3807288802095822\n",
            "Inner Loss:  0.007202394639274904\n",
            "Inner Loss:  0.0015961866094065563\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.33743524125644137\n",
            "Inner Loss:  0.016813592320042\n",
            "Inner Loss:  0.0034739228930058224\n",
            "Step: 11 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.36920444587511675\n",
            "Inner Loss:  0.06748794711061887\n",
            "Inner Loss:  0.05122149396421654\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4075062474501984\n",
            "Inner Loss:  0.0809466250772987\n",
            "Inner Loss:  0.018517733551561832\n",
            "Step: 12 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.47656872336353573\n",
            "Inner Loss:  0.08677736483514309\n",
            "Inner Loss:  0.009661311682845865\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4363688879779407\n",
            "Inner Loss:  0.012671108490654401\n",
            "Inner Loss:  0.0024513501806982924\n",
            "Step: 13 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2647450815087983\n",
            "Inner Loss:  0.004611554023410592\n",
            "Inner Loss:  0.0009766200590612634\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.6363603967641082\n",
            "Inner Loss:  0.022950657377285615\n",
            "Inner Loss:  0.004846636338957718\n",
            "Step: 14 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3542088931426406\n",
            "Inner Loss:  0.013783148556415523\n",
            "Inner Loss:  0.0016183943288134678\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.28259398685103015\n",
            "Inner Loss:  0.08297283814421721\n",
            "Inner Loss:  0.0053473844725106445\n",
            "Step: 15 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4939311019011906\n",
            "Inner Loss:  0.009850012471101113\n",
            "Inner Loss:  0.0016992590223838175\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.671344476485891\n",
            "Inner Loss:  0.0656801528696503\n",
            "Inner Loss:  0.004327734632949744\n",
            "Step: 16 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3023804848281933\n",
            "Inner Loss:  0.006205003575554916\n",
            "Inner Loss:  0.001502343619774495\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5434878152196428\n",
            "Inner Loss:  0.06536926089652947\n",
            "Inner Loss:  0.010187065894050258\n",
            "Step: 17 \ttraining Acc: 0.8\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5068638832973582\n",
            "Inner Loss:  0.011452274663107736\n",
            "Inner Loss:  0.0020113372510032995\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5658154040575027\n",
            "Inner Loss:  0.021637906187347004\n",
            "Inner Loss:  0.0027310658978032215\n",
            "Step: 18 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4389306539669633\n",
            "Inner Loss:  0.08392368496528693\n",
            "Inner Loss:  0.0633264843906675\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1668023101187178\n",
            "Inner Loss:  0.04468232752489192\n",
            "Inner Loss:  0.004875529291374343\n",
            "Step: 19 \ttraining Acc: 0.8\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3580638197516756\n",
            "Inner Loss:  0.01081383807052459\n",
            "Inner Loss:  0.0017583874453391349\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4044630978522556\n",
            "Inner Loss:  0.07793070375919342\n",
            "Inner Loss:  0.004480864619836211\n",
            "Step: 20 \ttraining Acc: 0.925\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22929488267982379\n",
            "Inner Loss:  0.004508284037001431\n",
            "Inner Loss:  0.0018339961534366012\n",
            "Inner Loss:  0.0012336382205830887\n",
            "Inner Loss:  0.0005432648031273857\n",
            "Inner Loss:  0.00036572911631083116\n",
            "Inner Loss:  0.00031102973298402503\n",
            "Inner Loss:  0.0002453219312883448\n",
            "Inner Loss:  0.00019763331874855794\n",
            "Inner Loss:  0.00018290607840754092\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.9691938502946869\n",
            "Inner Loss:  0.02786014461889863\n",
            "Inner Loss:  0.006903307978063822\n",
            "Inner Loss:  0.002857081010006368\n",
            "Inner Loss:  0.0018659855413716286\n",
            "Inner Loss:  0.0015278061910066754\n",
            "Inner Loss:  0.0011537654645508155\n",
            "Inner Loss:  0.0009804681612877175\n",
            "Inner Loss:  0.0008123133156914264\n",
            "Inner Loss:  0.0007483732333639637\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4280726138385944\n",
            "Inner Loss:  0.007691441802307963\n",
            "Inner Loss:  0.004577338928356767\n",
            "Inner Loss:  0.0020916701469104737\n",
            "Inner Loss:  0.0011617938725976273\n",
            "Inner Loss:  0.0008506587328156456\n",
            "Inner Loss:  0.0005363921009120531\n",
            "Inner Loss:  0.00043655325134750456\n",
            "Inner Loss:  0.00043269710295135155\n",
            "Inner Loss:  0.00035240182478446513\n",
            "Step: 20 Test F1: 0.8833333333333333\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5578761867114476\n",
            "Inner Loss:  0.05623307664479528\n",
            "Inner Loss:  0.003299106943554112\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.6723607499485037\n",
            "Inner Loss:  0.09653159922787122\n",
            "Inner Loss:  0.02828418164114867\n",
            "Step: 21 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4417812459703003\n",
            "Inner Loss:  0.007896115404686757\n",
            "Inner Loss:  0.0019727354436846717\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5301628063565919\n",
            "Inner Loss:  0.019203902089170048\n",
            "Inner Loss:  0.0020607354984219584\n",
            "Step: 22 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2821802324948034\n",
            "Inner Loss:  0.05360940777297531\n",
            "Inner Loss:  0.0029443250969052315\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5627698619583887\n",
            "Inner Loss:  0.060474789568356106\n",
            "Inner Loss:  0.024202645623258183\n",
            "Step: 23 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.35396994720213115\n",
            "Inner Loss:  0.008207377578530992\n",
            "Inner Loss:  0.001687574915454856\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.477654607567404\n",
            "Inner Loss:  0.05544133883501802\n",
            "Inner Loss:  0.0051309714492942604\n",
            "Step: 24 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4714812082903726\n",
            "Inner Loss:  0.006334509234875441\n",
            "Inner Loss:  0.0012783045448096736\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2765104263089597\n",
            "Inner Loss:  0.002622665770884071\n",
            "Inner Loss:  0.0010964247714062886\n",
            "Step: 25 \ttraining Acc: 0.7749999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.38946777542254757\n",
            "Inner Loss:  0.007826403847762517\n",
            "Inner Loss:  0.001957554669518556\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.44371467479504645\n",
            "Inner Loss:  0.01834165065416268\n",
            "Inner Loss:  0.0016215361787804536\n",
            "Step: 26 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5017173974109548\n",
            "Inner Loss:  0.01187879778444767\n",
            "Inner Loss:  0.00237990080911134\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.31989563150065287\n",
            "Inner Loss:  0.007068578952125141\n",
            "Inner Loss:  0.0014452093081282718\n",
            "Step: 27 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1778268601878413\n",
            "Inner Loss:  0.0036405973535563263\n",
            "Inner Loss:  0.0006424499692262284\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3443251663286771\n",
            "Inner Loss:  0.01617801029767309\n",
            "Inner Loss:  0.0018202231232342975\n",
            "Step: 28 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.23283462818445905\n",
            "Inner Loss:  0.00843677789505039\n",
            "Inner Loss:  0.0010393190896138549\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4832816951841648\n",
            "Inner Loss:  0.013746212369629316\n",
            "Inner Loss:  0.0025796095641063793\n",
            "Step: 29 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.40368315637377755\n",
            "Inner Loss:  0.007672571111470461\n",
            "Inner Loss:  0.0015817955302606737\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15507488438327396\n",
            "Inner Loss:  0.0012312693621164986\n",
            "Inner Loss:  0.0004093297175131738\n",
            "Step: 30 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5050253124209121\n",
            "Inner Loss:  0.10644615441560745\n",
            "Inner Loss:  0.019034295276339566\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5505764153120773\n",
            "Inner Loss:  0.056704395317605565\n",
            "Inner Loss:  0.0026024040499968188\n",
            "Step: 31 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.41652142429458244\n",
            "Inner Loss:  0.03728402492457202\n",
            "Inner Loss:  0.0023551372245752384\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27362097134547575\n",
            "Inner Loss:  0.006974122287439448\n",
            "Inner Loss:  0.0009340364569132882\n",
            "Step: 32 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.36722392286174\n",
            "Inner Loss:  0.007477297647190946\n",
            "Inner Loss:  0.0022194284247234464\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2070629123398768\n",
            "Inner Loss:  0.0012499018838363035\n",
            "Inner Loss:  0.0004466413270815143\n",
            "Step: 33 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.49043687752314974\n",
            "Inner Loss:  0.008534686639904976\n",
            "Inner Loss:  0.0010665751760825515\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.24397008107709034\n",
            "Inner Loss:  0.006933397679988827\n",
            "Inner Loss:  0.001479132949108524\n",
            "Step: 34 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5554129603219086\n",
            "Inner Loss:  0.07661322504281998\n",
            "Inner Loss:  0.005515353621116706\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2739322802850178\n",
            "Inner Loss:  0.004942872228899172\n",
            "Inner Loss:  0.0009213215089403093\n",
            "Step: 35 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.21322539904420929\n",
            "Inner Loss:  0.012674017543239253\n",
            "Inner Loss:  0.0008748864056542516\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.28885849339089226\n",
            "Inner Loss:  0.09570557331400258\n",
            "Inner Loss:  0.023424833048401133\n",
            "Step: 36 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.247991057112813\n",
            "Inner Loss:  0.05927884179566588\n",
            "Inner Loss:  0.006558136781677604\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22419664050851548\n",
            "Inner Loss:  0.0009250273828261665\n",
            "Inner Loss:  0.00035593022143335214\n",
            "Step: 37 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.27473731990903616\n",
            "Inner Loss:  0.002520874500208135\n",
            "Inner Loss:  0.000560009348971237\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.30567038603892016\n",
            "Inner Loss:  0.0030448644455256207\n",
            "Inner Loss:  0.000661707333555179\n",
            "Step: 38 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.32214733174935517\n",
            "Inner Loss:  0.00792198721319437\n",
            "Inner Loss:  0.001509773644751736\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2904852809983173\n",
            "Inner Loss:  0.0033416410608749303\n",
            "Inner Loss:  0.0006071087887643703\n",
            "Step: 39 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4038738320980753\n",
            "Inner Loss:  0.0031842949434316586\n",
            "Inner Loss:  0.0009794299174765392\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.17420870752539486\n",
            "Inner Loss:  0.001532779441082052\n",
            "Inner Loss:  0.00048385498147191744\n",
            "Step: 40 \ttraining Acc: 0.825\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.0770878586336039\n",
            "Inner Loss:  0.0005713216814910993\n",
            "Inner Loss:  0.0003917133290087804\n",
            "Inner Loss:  0.00023185608733911067\n",
            "Inner Loss:  0.00016587283244007267\n",
            "Inner Loss:  0.00012958124716533348\n",
            "Inner Loss:  0.00010663664943422191\n",
            "Inner Loss:  9.276250420953147e-05\n",
            "Inner Loss:  8.220305062422995e-05\n",
            "Inner Loss:  7.15651021891972e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6647375338943675\n",
            "Inner Loss:  0.015713463537395\n",
            "Inner Loss:  0.004320321953855455\n",
            "Inner Loss:  0.0017186740587931126\n",
            "Inner Loss:  0.0009834499505814165\n",
            "Inner Loss:  0.0005960419948678464\n",
            "Inner Loss:  0.00031293575011659414\n",
            "Inner Loss:  0.00023925330970087089\n",
            "Inner Loss:  0.00018965544586535543\n",
            "Inner Loss:  0.00018502078455640003\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.0870214095339179\n",
            "Inner Loss:  0.0018834337242878973\n",
            "Inner Loss:  0.0006938274163985625\n",
            "Inner Loss:  0.0005548611588892527\n",
            "Inner Loss:  0.0003345079021528363\n",
            "Inner Loss:  0.00025543519586790353\n",
            "Inner Loss:  0.0001930367470777128\n",
            "Inner Loss:  0.00017965536244446412\n",
            "Inner Loss:  0.0002618290855025407\n",
            "Inner Loss:  0.0001348897803836735\n",
            "Step: 40 Test F1: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11566214907881138\n",
            "Inner Loss:  0.0050454390168722186\n",
            "Inner Loss:  0.0005939537742441254\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.19089472453509057\n",
            "Inner Loss:  0.003721727956352489\n",
            "Inner Loss:  0.0007111730270220765\n",
            "Step: 41 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4697853611516101\n",
            "Inner Loss:  0.004536682407238654\n",
            "Inner Loss:  0.0013636134598138078\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2641242915332051\n",
            "Inner Loss:  0.0033710357965901494\n",
            "Inner Loss:  0.0006183277749057327\n",
            "Step: 42 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18481550864609225\n",
            "Inner Loss:  0.0020030959442790064\n",
            "Inner Loss:  0.00036752647221354503\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27991495175021036\n",
            "Inner Loss:  0.008072014166308301\n",
            "Inner Loss:  0.00115145870118535\n",
            "Step: 43 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20673563594131597\n",
            "Inner Loss:  0.0010864143509284727\n",
            "Inner Loss:  0.00043041034119336734\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16515357047319412\n",
            "Inner Loss:  0.0012044614372176252\n",
            "Inner Loss:  0.0004004793507712228\n",
            "Step: 44 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.49079029933948604\n",
            "Inner Loss:  0.04469816120607512\n",
            "Inner Loss:  0.003241795946710876\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1823767211753875\n",
            "Inner Loss:  0.05785347188689879\n",
            "Inner Loss:  0.015466859763754266\n",
            "Step: 45 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4307755591164875\n",
            "Inner Loss:  0.0058301872839885095\n",
            "Inner Loss:  0.0019116701358663185\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16949393525387027\n",
            "Inner Loss:  0.002463853602031512\n",
            "Inner Loss:  0.0006406728228154991\n",
            "Step: 46 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.25348727750991074\n",
            "Inner Loss:  0.0027654211569045272\n",
            "Inner Loss:  0.0009558212145098618\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3624567149922119\n",
            "Inner Loss:  0.060338911201272695\n",
            "Inner Loss:  0.016385169566742012\n",
            "Step: 47 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.13280270745911235\n",
            "Inner Loss:  0.0020006648181671543\n",
            "Inner Loss:  0.00030967386555857956\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.18235188476475223\n",
            "Inner Loss:  0.001005985649369125\n",
            "Inner Loss:  0.0003781758963928691\n",
            "Step: 48 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.28136778177161303\n",
            "Inner Loss:  0.0047001589887908524\n",
            "Inner Loss:  0.0008289319313397365\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.30372452130541205\n",
            "Inner Loss:  0.0016943537962755986\n",
            "Inner Loss:  0.0005317852441554091\n",
            "Step: 49 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5682657591699224\n",
            "Inner Loss:  0.02372220903635025\n",
            "Inner Loss:  0.004564748478255102\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.21162256698257156\n",
            "Inner Loss:  0.0014468880336997764\n",
            "Inner Loss:  0.0006429805320554546\n",
            "Step: 50 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.300037288240024\n",
            "Inner Loss:  0.0009568175384109574\n",
            "Inner Loss:  0.00034222718178560693\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3061069127704416\n",
            "Inner Loss:  0.0027178924564006074\n",
            "Inner Loss:  0.000625457988852369\n",
            "Step: 51 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.268521382207317\n",
            "Inner Loss:  0.005802773870527744\n",
            "Inner Loss:  0.0008902533861276295\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5229171734037144\n",
            "Inner Loss:  0.04887368942477873\n",
            "Inner Loss:  0.003752814672355141\n",
            "Step: 52 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.39049801543088897\n",
            "Inner Loss:  0.006619043448673827\n",
            "Inner Loss:  0.001000393705908209\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.23392690197631186\n",
            "Inner Loss:  0.0014428982062132231\n",
            "Inner Loss:  0.00027241195285958905\n",
            "Step: 53 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24751276443047182\n",
            "Inner Loss:  0.006444232072681189\n",
            "Inner Loss:  0.0013221224404073187\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4661565492195742\n",
            "Inner Loss:  0.0038489176825221095\n",
            "Inner Loss:  0.0013379904641104595\n",
            "Step: 54 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1838297385423045\n",
            "Inner Loss:  0.0014040129026398063\n",
            "Inner Loss:  0.0005497298344770181\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16656592963928624\n",
            "Inner Loss:  0.0009997881882424866\n",
            "Inner Loss:  0.0006190021397612457\n",
            "Step: 55 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24845727333532913\n",
            "Inner Loss:  0.001666384657645332\n",
            "Inner Loss:  0.0005468791018107108\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.08601569904879268\n",
            "Inner Loss:  0.0020257090883595602\n",
            "Inner Loss:  0.00027158332315074015\n",
            "Step: 56 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.41811862502280356\n",
            "Inner Loss:  0.004164620219463748\n",
            "Inner Loss:  0.000741348319154765\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.17549969613069802\n",
            "Inner Loss:  0.0021232767030596733\n",
            "Inner Loss:  0.00034354019486012736\n",
            "Step: 57 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.27686040141686263\n",
            "Inner Loss:  0.04164458119443485\n",
            "Inner Loss:  0.0025353625948940006\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3176384855593954\n",
            "Inner Loss:  0.005651092422860009\n",
            "Inner Loss:  0.0006800857123120555\n",
            "Step: 58 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18124417858780362\n",
            "Inner Loss:  0.000821794308389404\n",
            "Inner Loss:  0.0004266748728696257\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.24577401844518526\n",
            "Inner Loss:  0.003631780988403729\n",
            "Inner Loss:  0.0006820046484270799\n",
            "Step: 59 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.26555867632851005\n",
            "Inner Loss:  0.0024377163665901336\n",
            "Inner Loss:  0.005167583211524678\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.37430000530522584\n",
            "Inner Loss:  0.1680398051227842\n",
            "Inner Loss:  0.132607175303357\n",
            "Step: 60 \ttraining Acc: 0.8\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.19325922336429358\n",
            "Inner Loss:  0.0008658396982355043\n",
            "Inner Loss:  0.000502423441503197\n",
            "Inner Loss:  0.0002698799144127406\n",
            "Inner Loss:  0.00020873613539151847\n",
            "Inner Loss:  0.0001545141203678213\n",
            "Inner Loss:  0.0001310365660174284\n",
            "Inner Loss:  0.00012398901890264824\n",
            "Inner Loss:  9.688736463431269e-05\n",
            "Inner Loss:  9.328164742328227e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6279398217739072\n",
            "Inner Loss:  0.013105660676956177\n",
            "Inner Loss:  0.0026807835674844682\n",
            "Inner Loss:  0.001115158767788671\n",
            "Inner Loss:  0.000665154482703656\n",
            "Inner Loss:  0.000410986460337881\n",
            "Inner Loss:  0.00027518881688592955\n",
            "Inner Loss:  0.0002524906703911256\n",
            "Inner Loss:  0.00019313106895424426\n",
            "Inner Loss:  0.00018731469754129648\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.06894658671808429\n",
            "Inner Loss:  0.0008621912711532786\n",
            "Inner Loss:  0.00023085034627001733\n",
            "Inner Loss:  0.0001348126825178042\n",
            "Inner Loss:  0.000142176240842673\n",
            "Inner Loss:  7.540166916442104e-05\n",
            "Inner Loss:  6.0988461882516276e-05\n",
            "Inner Loss:  5.510284245247021e-05\n",
            "Inner Loss:  4.733478908747202e-05\n",
            "Inner Loss:  4.68751413791324e-05\n",
            "Step: 60 Test F1: 0.8666666666666667\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10183989961764642\n",
            "Inner Loss:  0.0005977405235171318\n",
            "Inner Loss:  0.00023381530315548713\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3349859544209072\n",
            "Inner Loss:  0.002663946444434779\n",
            "Inner Loss:  0.000738287327944168\n",
            "Step: 61 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2956923335857157\n",
            "Inner Loss:  0.007815606759062834\n",
            "Inner Loss:  0.0019939394800790717\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20194388161014235\n",
            "Inner Loss:  0.0011189928294957749\n",
            "Inner Loss:  0.0002431965965245451\n",
            "Step: 62 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.08315215633150988\n",
            "Inner Loss:  0.00045113098375233155\n",
            "Inner Loss:  0.00022266269037832638\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2039543590342094\n",
            "Inner Loss:  0.0021178775932639837\n",
            "Inner Loss:  0.0004431619308888912\n",
            "Step: 63 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2213823695534042\n",
            "Inner Loss:  0.002891413917365883\n",
            "Inner Loss:  0.00048464011550614875\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5068393883162311\n",
            "Inner Loss:  0.047008122982723374\n",
            "Inner Loss:  0.004819472603100751\n",
            "Step: 64 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3527044634351374\n",
            "Inner Loss:  0.004479809697451336\n",
            "Inner Loss:  0.0013578810695824878\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3424154913851193\n",
            "Inner Loss:  0.002219050407542714\n",
            "Inner Loss:  0.0008606051726798926\n",
            "Step: 65 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2548819797645722\n",
            "Inner Loss:  0.029984296499086276\n",
            "Inner Loss:  0.005745607577929539\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20503165340466825\n",
            "Inner Loss:  0.0025366873679948704\n",
            "Inner Loss:  0.0008025885409941631\n",
            "Step: 66 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.36171069707987563\n",
            "Inner Loss:  0.010242811005030359\n",
            "Inner Loss:  0.001563035334194345\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1576921629852482\n",
            "Inner Loss:  0.0007364183963675584\n",
            "Inner Loss:  0.00020506857046192245\n",
            "Step: 67 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.02652356031882976\n",
            "Inner Loss:  0.009382564632687718\n",
            "Inner Loss:  0.00010703096008260868\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3683178893656337\n",
            "Inner Loss:  0.01030921224238617\n",
            "Inner Loss:  0.0014826082957110234\n",
            "Step: 68 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2880168372232999\n",
            "Inner Loss:  0.0020969417777710725\n",
            "Inner Loss:  0.0005816525580095393\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15978504475372443\n",
            "Inner Loss:  0.003413783319826637\n",
            "Inner Loss:  0.0003957460867241025\n",
            "Step: 69 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4505863173232813\n",
            "Inner Loss:  0.007974420008914811\n",
            "Inner Loss:  0.0012458022018628462\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3585167356733499\n",
            "Inner Loss:  0.002293928393295833\n",
            "Inner Loss:  0.0006304901991305607\n",
            "Step: 70 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.33083956888211624\n",
            "Inner Loss:  0.008872808356370245\n",
            "Inner Loss:  0.00213732901361904\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3301642252315235\n",
            "Inner Loss:  0.00471298283498202\n",
            "Inner Loss:  0.0011075154512322374\n",
            "Step: 71 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.21561300781156337\n",
            "Inner Loss:  0.0010389135402095104\n",
            "Inner Loss:  0.000319124137084665\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5041729862402592\n",
            "Inner Loss:  0.05294319534940379\n",
            "Inner Loss:  0.004296648648700544\n",
            "Step: 72 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3053105403419717\n",
            "Inner Loss:  0.004889952384733728\n",
            "Inner Loss:  0.0008538445773800569\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15886383213468694\n",
            "Inner Loss:  0.0006086274682145033\n",
            "Inner Loss:  0.00033150584204122424\n",
            "Step: 73 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.16184302871780737\n",
            "Inner Loss:  0.000970656268431672\n",
            "Inner Loss:  0.0003245576600810247\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.07184149753967566\n",
            "Inner Loss:  0.0009201106149703264\n",
            "Inner Loss:  0.000324588649423926\n",
            "Step: 74 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1956397722200823\n",
            "Inner Loss:  0.0022923123989520328\n",
            "Inner Loss:  0.000649253446941397\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3167776476392256\n",
            "Inner Loss:  0.003475693686466132\n",
            "Inner Loss:  0.000663346893686269\n",
            "Step: 75 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11537460828964997\n",
            "Inner Loss:  0.0009944429704254226\n",
            "Inner Loss:  0.0003416968517870243\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4992357198415058\n",
            "Inner Loss:  0.006250246128599558\n",
            "Inner Loss:  0.001321754601251866\n",
            "Step: 76 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11871281601738051\n",
            "Inner Loss:  0.0010822589683812112\n",
            "Inner Loss:  0.00027996198332402855\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.24078231690717594\n",
            "Inner Loss:  0.0008874760408486639\n",
            "Inner Loss:  0.0003898714827041009\n",
            "Step: 77 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1550747155976881\n",
            "Inner Loss:  0.0011943206523678132\n",
            "Inner Loss:  0.00034108537199374823\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.298279452486895\n",
            "Inner Loss:  0.009101082238235645\n",
            "Inner Loss:  0.0009589692178581442\n",
            "Step: 78 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.32199642554457697\n",
            "Inner Loss:  0.005519023364675897\n",
            "Inner Loss:  0.0010728485150528805\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.17698963738179632\n",
            "Inner Loss:  0.0011487352395696299\n",
            "Inner Loss:  0.0005504041702287006\n",
            "Step: 79 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1569535140962606\n",
            "Inner Loss:  0.00371158796562148\n",
            "Inner Loss:  0.0005621871802889343\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.24040860671084374\n",
            "Inner Loss:  0.0028507996550095932\n",
            "Inner Loss:  0.0007429455955778914\n",
            "Step: 80 \ttraining Acc: 0.8999999999999999\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.0462851807824336\n",
            "Inner Loss:  0.00019606066416599788\n",
            "Inner Loss:  0.0001003315846901387\n",
            "Inner Loss:  7.504647510359064e-05\n",
            "Inner Loss:  5.928738210059237e-05\n",
            "Inner Loss:  4.53183183708461e-05\n",
            "Inner Loss:  4.1682579649204854e-05\n",
            "Inner Loss:  3.729934451257577e-05\n",
            "Inner Loss:  3.056675404877751e-05\n",
            "Inner Loss:  2.975219103973359e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.702299015945755\n",
            "Inner Loss:  0.007761508575640619\n",
            "Inner Loss:  0.0021032289951108396\n",
            "Inner Loss:  0.0011238937440793961\n",
            "Inner Loss:  0.000771244871430099\n",
            "Inner Loss:  0.0005764876113971695\n",
            "Inner Loss:  0.0004240689813741483\n",
            "Inner Loss:  0.00036298162740422413\n",
            "Inner Loss:  0.000289862604404334\n",
            "Inner Loss:  0.0002697329910006374\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.09710237491526641\n",
            "Inner Loss:  0.00033646595693426207\n",
            "Inner Loss:  0.00020625154138542712\n",
            "Inner Loss:  0.00014683616245747544\n",
            "Inner Loss:  0.0001204711697937455\n",
            "Inner Loss:  9.016235344461165e-05\n",
            "Inner Loss:  6.93671954650199e-05\n",
            "Inner Loss:  6.764130193914752e-05\n",
            "Inner Loss:  7.13274812369491e-05\n",
            "Inner Loss:  5.1270848416606896e-05\n",
            "Step: 80 Test F1: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22787464622940337\n",
            "Inner Loss:  0.0012543417895878\n",
            "Inner Loss:  0.0003943717747461051\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4631899848048176\n",
            "Inner Loss:  0.005036691170451897\n",
            "Inner Loss:  0.0017640271190819995\n",
            "Step: 81 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.011330874464225158\n",
            "Inner Loss:  0.00022047657746173042\n",
            "Inner Loss:  3.2670135884213126e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.44028474510248217\n",
            "Inner Loss:  0.0054606059566140175\n",
            "Inner Loss:  0.001647919333273811\n",
            "Step: 82 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.25810671827223686\n",
            "Inner Loss:  0.0070285129893038955\n",
            "Inner Loss:  0.0011750207049772143\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1975760321531977\n",
            "Inner Loss:  0.0006739717667057578\n",
            "Inner Loss:  0.0002486623728015859\n",
            "Step: 83 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.27111007177986074\n",
            "Inner Loss:  0.002820582328630345\n",
            "Inner Loss:  0.0005754969440334078\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.26668446397941026\n",
            "Inner Loss:  0.003084015566855669\n",
            "Inner Loss:  0.0010561878942618413\n",
            "Step: 84 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.25259813672995995\n",
            "Inner Loss:  0.0015979618599106158\n",
            "Inner Loss:  0.000439283562757607\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2817367829515466\n",
            "Inner Loss:  0.005538286208840353\n",
            "Inner Loss:  0.0007977053423279098\n",
            "Step: 85 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3193725059016807\n",
            "Inner Loss:  0.025082158590001718\n",
            "Inner Loss:  0.0025778800980853184\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.26801472015462685\n",
            "Inner Loss:  0.01602892328186759\n",
            "Inner Loss:  0.00205015590680497\n",
            "Step: 86 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.32979503127613236\n",
            "Inner Loss:  0.004266923326732857\n",
            "Inner Loss:  0.0007146235937917871\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2612073373581682\n",
            "Inner Loss:  0.0012605158678655113\n",
            "Inner Loss:  0.0003547938748462392\n",
            "Step: 87 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3428678640297481\n",
            "Inner Loss:  0.0015007789230107196\n",
            "Inner Loss:  0.0005641753544166152\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.33772666624281555\n",
            "Inner Loss:  0.010064500317509686\n",
            "Inner Loss:  0.0016348049477008836\n",
            "Step: 88 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1411004000027398\n",
            "Inner Loss:  0.0021961755784494536\n",
            "Inner Loss:  0.00021890190795862248\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.21379391849040985\n",
            "Inner Loss:  0.000669690127584285\n",
            "Inner Loss:  0.00028402450386368273\n",
            "Step: 89 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.07523385985820953\n",
            "Inner Loss:  0.00023947158687016263\n",
            "Inner Loss:  8.755636476312898e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.32208814894381377\n",
            "Inner Loss:  0.002000329616878714\n",
            "Inner Loss:  0.0005731469469277986\n",
            "Step: 90 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2096041748965425\n",
            "Inner Loss:  0.002482773835903832\n",
            "Inner Loss:  0.0010437605253952955\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2588695393476103\n",
            "Inner Loss:  0.005086370111842241\n",
            "Inner Loss:  0.000892061008406537\n",
            "Step: 91 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.050428009192858426\n",
            "Inner Loss:  0.0002379071364495238\n",
            "Inner Loss:  9.475001258709068e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.29435419304562466\n",
            "Inner Loss:  0.0022575525467150976\n",
            "Inner Loss:  0.0004059578267125679\n",
            "Step: 92 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3259559730067849\n",
            "Inner Loss:  0.0015072383102960885\n",
            "Inner Loss:  0.0004268359002058527\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.29175152889885275\n",
            "Inner Loss:  0.0028951429994776845\n",
            "Inner Loss:  0.0010048812504724733\n",
            "Step: 93 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3354572503428374\n",
            "Inner Loss:  0.0033889005093702246\n",
            "Inner Loss:  0.000712818033727152\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13391202523572637\n",
            "Inner Loss:  0.00040412797326488156\n",
            "Inner Loss:  0.00017791076970752329\n",
            "Step: 94 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.29815879884076174\n",
            "Inner Loss:  0.005485191176246319\n",
            "Inner Loss:  0.0011758949092057133\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27877479715139736\n",
            "Inner Loss:  0.0016005728809562112\n",
            "Inner Loss:  0.0005250646998839718\n",
            "Step: 95 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.14950301604611532\n",
            "Inner Loss:  0.08540586924313434\n",
            "Inner Loss:  0.0009733119846454688\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15608265069645963\n",
            "Inner Loss:  0.0009564165541503046\n",
            "Inner Loss:  0.00028225178331402797\n",
            "Step: 96 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11592758247362715\n",
            "Inner Loss:  0.0004889010867503073\n",
            "Inner Loss:  0.00025781752940799506\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2426452940063817\n",
            "Inner Loss:  0.0015264309975983842\n",
            "Inner Loss:  0.0004032241538100477\n",
            "Step: 97 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.17601259659776197\n",
            "Inner Loss:  0.003130057627069099\n",
            "Inner Loss:  0.0006463201134465635\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4295604968044375\n",
            "Inner Loss:  0.04676353864903961\n",
            "Inner Loss:  0.013944426950599467\n",
            "Step: 98 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3961601283933435\n",
            "Inner Loss:  0.002382827822917274\n",
            "Inner Loss:  0.0007223739438424153\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27249737389917883\n",
            "Inner Loss:  0.0026300843871597734\n",
            "Inner Loss:  0.0005807282494580639\n",
            "Step: 99 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10808942087792925\n",
            "Inner Loss:  0.0004782275687570551\n",
            "Inner Loss:  0.0002316439848592771\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22205138598967875\n",
            "Inner Loss:  0.0018814585637301207\n",
            "Inner Loss:  0.0002633650167678882\n",
            "Step: 100 \ttraining Acc: 0.975\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10567690746393055\n",
            "Inner Loss:  0.00030002780840732157\n",
            "Inner Loss:  0.0001848537940531969\n",
            "Inner Loss:  0.00013173640581953805\n",
            "Inner Loss:  0.00010856355947908014\n",
            "Inner Loss:  8.480111137032509e-05\n",
            "Inner Loss:  8.089468610705808e-05\n",
            "Inner Loss:  6.733837471983861e-05\n",
            "Inner Loss:  5.873353529750602e-05\n",
            "Inner Loss:  5.6180646424763836e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.7645648516408983\n",
            "Inner Loss:  0.008856726926751435\n",
            "Inner Loss:  0.0023323484929278493\n",
            "Inner Loss:  0.0011531881609698758\n",
            "Inner Loss:  0.0007886467647040263\n",
            "Inner Loss:  0.0006050822412362322\n",
            "Inner Loss:  0.0004514485626714304\n",
            "Inner Loss:  0.0003887838320224546\n",
            "Inner Loss:  0.0003131983175990172\n",
            "Inner Loss:  0.00030833469645585865\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11872366834722925\n",
            "Inner Loss:  0.0016808844957267866\n",
            "Inner Loss:  0.0003505777567625046\n",
            "Inner Loss:  0.00021976159769110382\n",
            "Inner Loss:  0.0001739301769703161\n",
            "Inner Loss:  0.00013060126184427645\n",
            "Inner Loss:  0.00010033633770945016\n",
            "Inner Loss:  9.787281487660948e-05\n",
            "Inner Loss:  0.0001269137628696626\n",
            "Inner Loss:  7.512849242630182e-05\n",
            "Step: 100 Test F1: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.35973831449103144\n",
            "Inner Loss:  0.012633990363350936\n",
            "Inner Loss:  0.0012563792572888946\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22810965067141556\n",
            "Inner Loss:  0.061415732821582684\n",
            "Inner Loss:  0.001534101919138006\n",
            "Step: 101 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18800673464180104\n",
            "Inner Loss:  0.0009721125659000661\n",
            "Inner Loss:  0.00024303628015331924\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.012250459399573239\n",
            "Inner Loss:  4.090270470312264e-05\n",
            "Inner Loss:  2.4964794907386283e-05\n",
            "Step: 102 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24898110968726023\n",
            "Inner Loss:  0.0019834383108120945\n",
            "Inner Loss:  0.00037582910694514534\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22652488737367094\n",
            "Inner Loss:  0.006865598826802203\n",
            "Inner Loss:  0.00047877653768020015\n",
            "Step: 103 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4886118297664715\n",
            "Inner Loss:  0.00369201141542622\n",
            "Inner Loss:  0.0011437923780509404\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1643363065917843\n",
            "Inner Loss:  0.023235903720238378\n",
            "Inner Loss:  0.001299177437821137\n",
            "Step: 104 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.23587866399403928\n",
            "Inner Loss:  0.0023879800158153686\n",
            "Inner Loss:  0.0004936322636370148\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1813604444074112\n",
            "Inner Loss:  0.0021368421813739197\n",
            "Inner Loss:  0.0005116552305740438\n",
            "Step: 105 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.26371639016101006\n",
            "Inner Loss:  0.00984810379200748\n",
            "Inner Loss:  0.001173564191308937\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.39500063622836024\n",
            "Inner Loss:  0.10040956655783313\n",
            "Inner Loss:  0.031751883149679215\n",
            "Step: 106 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24180273705029062\n",
            "Inner Loss:  0.0035148715666894403\n",
            "Inner Loss:  0.001016939408145845\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.14867416221698346\n",
            "Inner Loss:  0.0008514466462656856\n",
            "Inner Loss:  0.00034103576659357974\n",
            "Step: 107 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18088763932298338\n",
            "Inner Loss:  0.0011493791327146547\n",
            "Inner Loss:  0.00037276851695163975\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.33452279147292885\n",
            "Inner Loss:  0.001601022302306124\n",
            "Inner Loss:  0.0005247204348311893\n",
            "Step: 108 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.05874997578627829\n",
            "Inner Loss:  0.00022150185291788409\n",
            "Inner Loss:  0.000131937324892663\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.28299551877924906\n",
            "Inner Loss:  0.003216065582819283\n",
            "Inner Loss:  0.0007463223467181836\n",
            "Step: 109 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.17223632209269063\n",
            "Inner Loss:  0.007136180930371795\n",
            "Inner Loss:  0.0006930419102510703\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1482026781138432\n",
            "Inner Loss:  0.0012893168646509626\n",
            "Inner Loss:  0.0002812116643846301\n",
            "Step: 110 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2569144123366901\n",
            "Inner Loss:  0.0007280741286064897\n",
            "Inner Loss:  0.0002825001782704411\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.10793090971752203\n",
            "Inner Loss:  0.0023725739530553775\n",
            "Inner Loss:  0.000422187103790098\n",
            "Step: 111 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20576601379018808\n",
            "Inner Loss:  0.038301040551492145\n",
            "Inner Loss:  0.001960840683230864\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2960248751499291\n",
            "Inner Loss:  0.007596081189279046\n",
            "Inner Loss:  0.0016328357991629414\n",
            "Step: 112 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.007253467762244067\n",
            "Inner Loss:  4.268319857406563e-05\n",
            "Inner Loss:  2.964281130906394e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.29131646673860295\n",
            "Inner Loss:  0.003950945334509015\n",
            "Inner Loss:  0.0011857770732603967\n",
            "Step: 113 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3442193626293114\n",
            "Inner Loss:  0.003831147133106632\n",
            "Inner Loss:  0.001320402154565922\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4612792856226276\n",
            "Inner Loss:  0.007316595874726772\n",
            "Inner Loss:  0.0016478338677968299\n",
            "Step: 114 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24018702782424434\n",
            "Inner Loss:  0.0018103793596050569\n",
            "Inner Loss:  0.0006437504863632577\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20999765800245637\n",
            "Inner Loss:  0.0012724506336131266\n",
            "Inner Loss:  0.00048125245458712537\n",
            "Step: 115 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22518858815809445\n",
            "Inner Loss:  0.0008350857616668301\n",
            "Inner Loss:  0.0004800767845673753\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3240082757630652\n",
            "Inner Loss:  0.003602238604798913\n",
            "Inner Loss:  0.0009432323692765619\n",
            "Step: 116 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3260185695003851\n",
            "Inner Loss:  0.05687273519911936\n",
            "Inner Loss:  0.004285265625055347\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.30582108228866545\n",
            "Inner Loss:  0.020049948877255832\n",
            "Inner Loss:  0.0017485049154077256\n",
            "Step: 117 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.25261292724670575\n",
            "Inner Loss:  0.002743731701879629\n",
            "Inner Loss:  0.000786502704223884\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22127905966148578\n",
            "Inner Loss:  0.0013554288722973848\n",
            "Inner Loss:  0.0005640021866253976\n",
            "Step: 118 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10356184349594903\n",
            "Inner Loss:  0.0011622652195260993\n",
            "Inner Loss:  0.000478311803557777\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.10282820270263723\n",
            "Inner Loss:  0.0005720544806016343\n",
            "Inner Loss:  0.0003093116496789402\n",
            "Step: 119 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.13297617849145485\n",
            "Inner Loss:  0.0015288413602060505\n",
            "Inner Loss:  0.0004218351761145251\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13222471105733088\n",
            "Inner Loss:  0.00041443403045247706\n",
            "Inner Loss:  0.00018963716034444848\n",
            "Step: 120 \ttraining Acc: 0.925\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11094626155681908\n",
            "Inner Loss:  0.00038407590182032436\n",
            "Inner Loss:  0.0002058846985164564\n",
            "Inner Loss:  0.00016851619147928432\n",
            "Inner Loss:  0.0001264280563191278\n",
            "Inner Loss:  9.87771745712962e-05\n",
            "Inner Loss:  9.135703476204071e-05\n",
            "Inner Loss:  7.9608578744228e-05\n",
            "Inner Loss:  6.783016397093888e-05\n",
            "Inner Loss:  6.613647929043509e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.752105547071551\n",
            "Inner Loss:  0.0046690828166902065\n",
            "Inner Loss:  0.0025969896814785898\n",
            "Inner Loss:  0.0012104602938052267\n",
            "Inner Loss:  0.0008840119990054518\n",
            "Inner Loss:  0.0006461115117417648\n",
            "Inner Loss:  0.0005220716848270968\n",
            "Inner Loss:  0.0004258598783053458\n",
            "Inner Loss:  0.00032529271265957505\n",
            "Inner Loss:  0.00031660077365813777\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10053610059549101\n",
            "Inner Loss:  0.000449638617283199\n",
            "Inner Loss:  0.00021148466476006433\n",
            "Inner Loss:  0.00015588469977956265\n",
            "Inner Loss:  0.0001284823792957468\n",
            "Inner Loss:  0.00010095224388351198\n",
            "Inner Loss:  7.800673483870924e-05\n",
            "Inner Loss:  7.432648999383673e-05\n",
            "Inner Loss:  6.734564612997929e-05\n",
            "Inner Loss:  5.9098466408613604e-05\n",
            "Step: 120 Test F1: 0.9333333333333332\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.16146872312362706\n",
            "Inner Loss:  0.0009425222025518971\n",
            "Inner Loss:  0.00036692831365923794\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15541426167224667\n",
            "Inner Loss:  0.004639398152773667\n",
            "Inner Loss:  0.0010065573359107865\n",
            "Step: 121 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.36852534780544893\n",
            "Inner Loss:  0.004720042359882167\n",
            "Inner Loss:  0.0013839087249445064\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13029793622471125\n",
            "Inner Loss:  0.000942266737443528\n",
            "Inner Loss:  0.00039747716592890877\n",
            "Step: 122 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2933856897787856\n",
            "Inner Loss:  0.008786830119788647\n",
            "Inner Loss:  0.0013877043799896324\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.08696040610915848\n",
            "Inner Loss:  0.0002066340946060206\n",
            "Inner Loss:  0.00012210051811832403\n",
            "Step: 123 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.07719351536278347\n",
            "Inner Loss:  0.0002697861158854461\n",
            "Inner Loss:  0.00022046279419945286\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.10316072293790057\n",
            "Inner Loss:  0.002131734779270898\n",
            "Inner Loss:  0.00036994613765273243\n",
            "Step: 124 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3873990095037568\n",
            "Inner Loss:  0.006256674349840198\n",
            "Inner Loss:  0.0007996278000064194\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22124661824532918\n",
            "Inner Loss:  0.002607331195447062\n",
            "Inner Loss:  0.0005984596542215773\n",
            "Step: 125 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4223439316265285\n",
            "Inner Loss:  0.05986549731876169\n",
            "Inner Loss:  0.003422566972273801\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.29359373629891444\n",
            "Inner Loss:  0.0010816648885208582\n",
            "Inner Loss:  0.0004731100468364145\n",
            "Step: 126 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4283959603469287\n",
            "Inner Loss:  0.007429121827174511\n",
            "Inner Loss:  0.0015528990936997747\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16512059766267026\n",
            "Inner Loss:  0.0016915674454399518\n",
            "Inner Loss:  0.00046593742860880284\n",
            "Step: 127 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.15495911879198893\n",
            "Inner Loss:  0.0008065278359156634\n",
            "Inner Loss:  0.000356326241412067\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20870710386329197\n",
            "Inner Loss:  0.0018574784875714353\n",
            "Inner Loss:  0.0006166697255269225\n",
            "Step: 128 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2043498465209268\n",
            "Inner Loss:  0.0006313323725147971\n",
            "Inner Loss:  0.0005392642924562097\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13570273030615812\n",
            "Inner Loss:  0.000492424371519259\n",
            "Inner Loss:  0.0003561961410533903\n",
            "Step: 129 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3323082239034453\n",
            "Inner Loss:  0.004643539299390146\n",
            "Inner Loss:  0.0011612877382763795\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.44524755219130646\n",
            "Inner Loss:  0.0029767572081514765\n",
            "Inner Loss:  0.0011609390494413674\n",
            "Step: 130 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3082305758393237\n",
            "Inner Loss:  0.01449177460744977\n",
            "Inner Loss:  0.0015972433944365808\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.12227887284409787\n",
            "Inner Loss:  0.0008180865136507366\n",
            "Inner Loss:  0.00036763495466272743\n",
            "Step: 131 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2940044387110642\n",
            "Inner Loss:  0.005520834654037442\n",
            "Inner Loss:  0.0013473308478881205\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2569454359722191\n",
            "Inner Loss:  0.002352865246523704\n",
            "Inner Loss:  0.0007993984742954906\n",
            "Step: 132 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11095512776436019\n",
            "Inner Loss:  0.0010855351574718952\n",
            "Inner Loss:  0.0003174683453315603\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20818221458466724\n",
            "Inner Loss:  0.0021542521176992784\n",
            "Inner Loss:  0.0007087160483933985\n",
            "Step: 133 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24986810129900863\n",
            "Inner Loss:  0.006259534774082047\n",
            "Inner Loss:  0.0012255446552964194\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3525152142558779\n",
            "Inner Loss:  0.003479037101247481\n",
            "Inner Loss:  0.0007946218829602003\n",
            "Step: 134 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.008499802114134323\n",
            "Inner Loss:  0.03145049799942561\n",
            "Inner Loss:  6.251670025189274e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.28451136050612796\n",
            "Inner Loss:  0.002422208515261965\n",
            "Inner Loss:  0.0005674490655240204\n",
            "Step: 135 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22781692721348787\n",
            "Inner Loss:  0.006644071811544043\n",
            "Inner Loss:  0.0006719667996679034\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.19289892960971752\n",
            "Inner Loss:  0.0024978309853135477\n",
            "Inner Loss:  0.00035075851649578126\n",
            "Step: 136 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.19748809297120065\n",
            "Inner Loss:  0.04064445037926946\n",
            "Inner Loss:  0.001483230693598411\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2463470617575305\n",
            "Inner Loss:  0.0018014593016622321\n",
            "Inner Loss:  0.0006710542033293418\n",
            "Step: 137 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.14474286453956406\n",
            "Inner Loss:  0.0018685200151854328\n",
            "Inner Loss:  0.0006089955526736698\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1431924232248483\n",
            "Inner Loss:  0.0010110065839918597\n",
            "Inner Loss:  0.0003451854323170015\n",
            "Step: 138 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.06372826948894986\n",
            "Inner Loss:  0.000290759901482878\n",
            "Inner Loss:  0.0001371251658253771\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.33795454406312536\n",
            "Inner Loss:  0.00351056143907564\n",
            "Inner Loss:  0.0008917264058254659\n",
            "Step: 139 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.14750972657930106\n",
            "Inner Loss:  0.0010818811881888127\n",
            "Inner Loss:  0.0004160502825730613\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.17317751785075025\n",
            "Inner Loss:  0.0010215929027513734\n",
            "Inner Loss:  0.0004046975061230894\n",
            "Step: 140 \ttraining Acc: 1.0\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.137485614977777\n",
            "Inner Loss:  0.000666899373754859\n",
            "Inner Loss:  0.00046863334864610806\n",
            "Inner Loss:  0.00036197146982885897\n",
            "Inner Loss:  0.0003162564316880889\n",
            "Inner Loss:  0.00023245405463967472\n",
            "Inner Loss:  0.00021319063307601027\n",
            "Inner Loss:  0.0001786178327165544\n",
            "Inner Loss:  0.0001589418825460598\n",
            "Inner Loss:  0.00014697862934553996\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6562936642658315\n",
            "Inner Loss:  0.002907148329541087\n",
            "Inner Loss:  0.001789098372682929\n",
            "Inner Loss:  0.0008381894294871017\n",
            "Inner Loss:  0.0006376459787134081\n",
            "Inner Loss:  0.00048414435877930373\n",
            "Inner Loss:  0.00039056465902831405\n",
            "Inner Loss:  0.00033225423976546153\n",
            "Inner Loss:  0.0002638066216604784\n",
            "Inner Loss:  0.00024743436006247066\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.049706872552633286\n",
            "Inner Loss:  0.00026159899789490737\n",
            "Inner Loss:  0.0001500425314588938\n",
            "Inner Loss:  0.00012626844363694545\n",
            "Inner Loss:  9.917391616909299e-05\n",
            "Inner Loss:  8.344760863110423e-05\n",
            "Inner Loss:  6.68143011353095e-05\n",
            "Inner Loss:  6.243878124223556e-05\n",
            "Inner Loss:  5.430812507256633e-05\n",
            "Inner Loss:  5.0625286348804366e-05\n",
            "Step: 140 Test F1: 0.9333333333333332\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.13707826227930905\n",
            "Inner Loss:  0.0015262584825645068\n",
            "Inner Loss:  0.000250855356820726\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20149213022419385\n",
            "Inner Loss:  0.004997867758252791\n",
            "Inner Loss:  0.0006906476004847459\n",
            "Step: 141 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.17095785949745082\n",
            "Inner Loss:  0.003314197254699788\n",
            "Inner Loss:  0.00035402960825844536\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.09879340191504785\n",
            "Inner Loss:  0.000581653173347669\n",
            "Inner Loss:  0.000305925148755445\n",
            "Step: 142 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4315827257399048\n",
            "Inner Loss:  0.005461790399359805\n",
            "Inner Loss:  0.0012116660197664584\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.04154683944528058\n",
            "Inner Loss:  8.912234729255683e-05\n",
            "Inner Loss:  0.044517276683369085\n",
            "Step: 143 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.17955748159770987\n",
            "Inner Loss:  0.005991526646539569\n",
            "Inner Loss:  0.0009462299473982837\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.23399540870117821\n",
            "Inner Loss:  0.005164789351900774\n",
            "Inner Loss:  0.0007657310010732285\n",
            "Step: 144 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3920576406443225\n",
            "Inner Loss:  0.004804739695308464\n",
            "Inner Loss:  0.0012783780943469278\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.524392426812223\n",
            "Inner Loss:  0.056636521858828406\n",
            "Inner Loss:  0.010831553089831556\n",
            "Step: 145 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.04373115683847573\n",
            "Inner Loss:  0.00018796112791668356\n",
            "Inner Loss:  8.877471970793392e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.19943918666935392\n",
            "Inner Loss:  0.001296120388100722\n",
            "Inner Loss:  0.0005594614361013685\n",
            "Step: 146 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2464246487777148\n",
            "Inner Loss:  0.001333933897382979\n",
            "Inner Loss:  0.00047966479074342975\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.18513390941578628\n",
            "Inner Loss:  0.001538411115429231\n",
            "Inner Loss:  0.0005394525900815747\n",
            "Step: 147 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22172056145167776\n",
            "Inner Loss:  0.0025367406363199863\n",
            "Inner Loss:  0.0008874091685616545\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1122908359331112\n",
            "Inner Loss:  0.001064922394497054\n",
            "Inner Loss:  0.0003180900156231863\n",
            "Step: 148 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3881400967282908\n",
            "Inner Loss:  0.0347437539270946\n",
            "Inner Loss:  0.001888807862997055\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13881111490939343\n",
            "Inner Loss:  0.0010099777885313546\n",
            "Inner Loss:  0.00040205126528495124\n",
            "Step: 149 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24358003411907703\n",
            "Inner Loss:  0.0021844355755352546\n",
            "Inner Loss:  0.000691874380988468\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2435744291703616\n",
            "Inner Loss:  0.0007641248271933623\n",
            "Inner Loss:  0.00044364825589582324\n",
            "Step: 150 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2539783827960491\n",
            "Inner Loss:  0.002500681173322456\n",
            "Inner Loss:  0.0006831437931396067\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-745c479b68d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\ttraining Acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f2675dbeff1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_tasks, training)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mfast_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfast_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: \n",
        "1) https://github.com/mailong25/meta-learning-bert/blob/master/Interactive.ipynb"
      ],
      "metadata": {
        "id": "tSUd7ahBwQ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZqj6iY7AQZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}